{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.240 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.223 ğŸš€ Python-3.12.5 torch-2.2.2 CPU (Intel Core i5-5350U 1.80GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/Users/janamac/Documents/project1/parking/clf-data, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=64, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/runs/classify/train4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "WARNING âš ï¸ Dataset 'split=train' not found at /Users/janamac/Documents/project1/parking/clf-data/train\n",
      "Found 6090 images in subdirectories. Attempting to split...\n",
      "Splitting /Users/janamac/Documents/project1/parking/clf-data (2 classes, 6092 images) into 80% train, 20% val...\n",
      "Split complete in /Users/janamac/Documents/project1/parking/clf-data_split âœ…\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/janamac/Documents/project1/parking/clf-data_split/train... found 4871 images in 2 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/janamac/Documents/project1/parking/clf-data_split/val... found 1219 images in 2 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
      "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.1Â±0.0 ms, read: 1.0Â±0.9 MB/s, size: 1.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/janamac/Documents/project1/parking/clf-data_split/train... 4871 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4871/4871 812.1it/s 6.0s<0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/janamac/Documents/project1/parking/clf-data_split/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3.0Â±1.4 MB/s, size: 1.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/janamac/Documents/project1/parking/clf-data_split/val... 1219 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1219/1219 877.7it/s 1.4s.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/janamac/Documents/project1/parking/clf-data_split/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 64 train, 64 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/runs/classify/train4\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       1/15         0G     0.8786         16         64: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/305  0.8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/15         0G     0.2444          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 2.2it/s 2:21<0.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 6.5it/s 6.0s0.2s\n",
      "                   all      0.994          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       2/15         0G    0.04206          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 2.3it/s 2:12<0.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 6.6it/s 5.9s0.1s\n",
      "                   all      0.996          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       3/15         0G    0.05081          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 2.8it/s 1:47<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 6.0it/s 6.5s0.1s\n",
      "                   all      0.976          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       4/15         0G    0.03587          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 2.7it/s 1:52<0.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 6.0it/s 6.5s0.2s\n",
      "                   all          1          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       5/15         0G    0.02927          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 2.5it/s 2:04<0.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 5.2it/s 7.5s0.2s\n",
      "                   all      0.995          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       6/15         0G    0.01582          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 2.9it/s 1:45<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 6.7it/s 5.9s0.2s\n",
      "                   all      0.998          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       7/15         0G    0.01654          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 3.5it/s 1:28<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 7.2it/s 5.4s0.1s\n",
      "                   all      0.998          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       8/15         0G    0.02744          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 3.5it/s 1:27<0.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 4.4it/s 8.8s0.1s\n",
      "                   all      0.999          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       9/15         0G    0.01406          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 3.7it/s 1:22<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 7.0it/s 5.6s0.1s\n",
      "                   all      0.999          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      10/15         0G   0.005993          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 3.8it/s 1:20<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 6.9it/s 5.6s0.1s\n",
      "                   all          1          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      11/15         0G     0.0148          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 3.7it/s 1:23<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 5.8it/s 6.8s0.2s\n",
      "                   all      0.999          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      12/15         0G   0.006861          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 3.4it/s 1:29<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 7.2it/s 5.4s0.1s\n",
      "                   all      0.999          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      13/15         0G   0.008598          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 4.2it/s 1:12<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 7.4it/s 5.3s0.1s\n",
      "                   all      0.999          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      14/15         0G   0.006207          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 3.1it/s 1:39<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 7.1it/s 5.5s0.1s\n",
      "                   all          1          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      15/15         0G   0.004587          7         64: 100% â”â”â”â”â”â”â”â”â”â”â”â” 305/305 4.1it/s 1:14<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 7.3it/s 5.3s0.1s\n",
      "                   all          1          1\n",
      "\n",
      "15 epochs completed in 0.438 hours.\n",
      "Optimizer stripped from /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/runs/classify/train4/weights/last.pt, 3.0MB\n",
      "Optimizer stripped from /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/runs/classify/train4/weights/best.pt, 3.0MB\n",
      "\n",
      "Validating /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/runs/classify/train4/weights/best.pt...\n",
      "Ultralytics 8.3.223 ğŸš€ Python-3.12.5 torch-2.2.2 CPU (Intel Core i5-5350U 1.80GHz)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
      "WARNING âš ï¸ Dataset 'split=train' not found at /Users/janamac/Documents/project1/parking/clf-data/train\n",
      "Found 6090 images in subdirectories. Attempting to split...\n",
      "Splitting /Users/janamac/Documents/project1/parking/clf-data (2 classes, 6092 images) into 80% train, 20% val...\n",
      "Split complete in /Users/janamac/Documents/project1/parking/clf-data_split âœ…\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/janamac/Documents/project1/parking/clf-data_split/train... found 5847 images in 2 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/janamac/Documents/project1/parking/clf-data_split/val... found 2195 images in 2 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 39/39 5.8it/s 6.7s0.1s\n",
      "                   all          1          1\n",
      "Speed: 0.0ms preprocess, 2.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/runs/classify/train4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x128e82a80>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 1.0\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 1.0, 'metrics/accuracy_top5': 1.0, 'fitness': 1.0}\n",
       "save_dir: PosixPath('/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/runs/classify/train4')\n",
       "speed: {'preprocess': 0.002120297786450129, 'inference': 2.3563838392111944, 'loss': 4.8893356308133986e-05, 'postprocess': 0.00017075225312225147}\n",
       "task: 'classify'\n",
       "top1: 1.0\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø®ØµØµ Ù„Ù„ØªØµÙ†ÙŠÙ (Suffix -cls)\n",
    "model = YOLO('yolov8n-cls.pt')\n",
    "\n",
    "data_path = '/Users/janamac/Documents/project1/parking/clf-data' \n",
    "\n",
    "# 3. Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
    "model.train(\n",
    "    data=data_path,\n",
    "    epochs=15,\n",
    "    imgsz=64,\n",
    "    model='yolov8n-cls.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ù…Ø§Ø³Ùƒ\n",
    "model = YOLO('/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/runs/classify/train4/weights/best.pt')\n",
    "mask = cv2.imread('/Users/janamac/Documents/project1/parking/mask_1920_1080.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "parking_image = cv2.imread('/Users/janamac/Documents/parking.png')\n",
    "parking_image = cv2.resize(parking_image, (1920, 1080)) # Ø¯ÙŠ Ø£Ù‡Ù… Ø®Ø·ÙˆØ© Ù„Ù„Ø¶Ø¨Ø·\n",
    "\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    \n",
    "    # Ù‡Ù†Ù‚Øµ Ø§Ù„Ø±ÙƒÙ†Ø© Ù…Ø¹ \"Ù‡Ø§Ù…Ø´\" ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹ Ø¹Ø´Ø§Ù† Ù†Ø¶Ù…Ù† Ø¥Ù†Ù†Ø§ Ø¬ÙˆÙ‡ Ø§Ù„Ù…Ø±Ø¨Ø¹\n",
    "    slot_crop = parking_image[y:y+h, x:x+w]\n",
    "    \n",
    "    if slot_crop.size > 0:\n",
    "        # ØªØµÙ†ÙŠÙ Ø§Ù„Ø±ÙƒÙ†Ø©\n",
    "        results = model(slot_crop, verbose=False)\n",
    "        probs = results[0].probs\n",
    "        label = results[0].names[probs.top1]\n",
    "        conf = probs.top1conf.item() # Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ£ÙƒØ¯\n",
    "\n",
    "        # Ø¶Ø¨Ø· Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©: Ù„Ùˆ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø´ Ù…ØªØ£ÙƒØ¯ Ø£ÙˆÙŠØŒ Ø§Ø¹ØªØ¨Ø±Ù‡Ø§ \"Ù…Ø´ Ù…Ø¹Ø±ÙˆÙØ©\" Ø£Ùˆ Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ù„ÙˆÙ†\n",
    "        if conf > 0.7: # Ø¨Ù†Ø²ÙˆØ¯ Ø§Ù„Ù€ Confidence threshold Ø¹Ø´Ø§Ù† Ø§Ù„Ø¯Ù‚Ø©\n",
    "            color = (0, 255, 0) if label == 'empty' else (0, 0, 255)\n",
    "            cv2.rectangle(parking_image, (x, y), (x+w, y+h), color, 2)\n",
    "\n",
    "# 4. Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©\n",
    "cv2.imshow('Fixed Detection', parking_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 bus, 11 cell phones, 260.2ms\n",
      "Speed: 8.7ms preprocess, 260.2ms inference, 7.4ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ YOLOv8 Ø§Ù„Ù…ØªØ¯Ø±Ø¨ Ø¹Ù„Ù‰ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ§Øª Ù…Ø«Ù„Ø§Ù‹)\n",
    "model = YOLO('yolov8n.pt') \n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±ØªÙƒ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©\n",
    "img = cv2.imread('/Users/janamac/Documents/project1/archive (1)/boxes/0.png')\n",
    "\n",
    "# Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ§Øª ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©\n",
    "results = model(img)\n",
    "\n",
    "# Ø±Ø³Ù… Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    for box in boxes:\n",
    "        # Ø§Ù„ÙƒÙ„Ø§Ø³ Ø±Ù‚Ù… 2 ÙÙŠ YOLO Ù‡Ùˆ 'car' ÙˆØ±Ù‚Ù… 7 Ù‡Ùˆ 'truck'\n",
    "        if box.cls[0] in [2, 7]: \n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            # Ø±Ø³Ù… Ù…Ø±Ø¨Ø¹ Ø£Ø­Ù…Ø± Ø­ÙˆÙ„ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©\n",
    "            cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow('Detection Result', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Ø§Ù„Ø³Ø·Ø± Ø¯Ù‡ Ø¨ÙŠØ­Ù„ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶ ÙÙŠ Ø§Ù„Ù…Ø§Ùƒ ÙˆØ³Ø§Ø¹Ø§Øª Ø¨ÙŠÙ…Ù†Ø¹ Ø§Ù„Ù€ Crash\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ù…Ø§Ø³Ùƒ\n",
    "model = YOLO('/Users/janamac/Documents/project1/parking/best.pt')\n",
    "mask = cv2.imread('/Users/janamac/Documents/project1/parking/mask_1920_1080.png', cv2.IMREAD_GRAYSCALE)\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cap = cv2.VideoCapture('/Users/janamac/Documents/project1/parking/parking_1920_1080_loop.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    frame = cv2.resize(frame, (1920, 1080))\n",
    "    empty_slots = 0\n",
    "\n",
    "    # Ø£Ù‡Ù… ØªØ¹Ø¯ÙŠÙ„: verbose=False Ø¹Ø´Ø§Ù† Ù…ÙŠØ¨Ø¹ØªØ´ Ø¢Ù„Ø§Ù Ø§Ù„Ø³Ø·ÙˆØ± Ù„Ù„Ù€ VS Code ÙˆÙŠÙ‚Ø¹Ù‡\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 20 and h > 20:\n",
    "            slot_crop = frame[y:y+h, x:x+w]\n",
    "            # verbose=False Ù‡Ùˆ Ø§Ù„Ø³Ø± Ù‡Ù†Ø§\n",
    "            results = model.predict(slot_crop, verbose=False, device='cpu') \n",
    "            \n",
    "            label = results[0].names[results[0].probs.top1]\n",
    "            color = (0, 255, 0) if label == 'empty' else (0, 0, 255)\n",
    "            if label == 'empty': empty_slots += 1\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "\n",
    "    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©\n",
    "    cv2.imshow('Smart Parking Monitor', cv2.resize(frame, (1280, 720)))\n",
    "    \n",
    "    # Ø§Ù„Ø®Ø±ÙˆØ¬ Ø§Ù„Ø¢Ù…Ù†\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1) # Ø³Ø·Ø± Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„Ù…Ø§Ùƒ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
